from fastapi import FastAPI, Query
import requests
from fastapi.middleware.cors import CORSMiddleware
import re
import asyncio

app = FastAPI()

# âœ… Activer CORS pour autoriser les requÃªtes du frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ðŸ“Œ URL de l'API Hugging Face
API_URL = "https://datasets-server.huggingface.co/rows"
DATASET_NAME = "Abirate/english_quotes"

# âœ… Cache global pour Ã©viter de refaire des requÃªtes inutiles
cached_quotes = []
fetch_lock = asyncio.Lock()  # âœ… Verrou pour Ã©viter le double chargement

async def fetch_quotes():
    global cached_quotes
    async with fetch_lock:  # âœ… EmpÃªche les requÃªtes simultanÃ©es
        if cached_quotes:  # âœ… VÃ©rifie si le cache est dÃ©jÃ  rempli
            print(f"âœ… Cache dÃ©jÃ  chargÃ© ({len(cached_quotes)} citations). Pas de nouvelle rÃ©cupÃ©ration.")
            return cached_quotes  

        print("ðŸ“Œ Chargement des citations depuis l'API (par lots de 100)...")
        total_quotes = []
        offset = 0
        batch_size = 100  # L'API limite length Ã  100
        max_quotes = 5000  # Nombre total de citations Ã  rÃ©cupÃ©rer

        while len(total_quotes) < max_quotes and offset < 5000:
            params = {
                "dataset": DATASET_NAME,
                "config": "default",
                "split": "train",
                "offset": offset,
                "length": batch_size
            }

            response = requests.get(API_URL, params=params)
            if response.status_code != 200:
                print(f"âš ï¸ Erreur API: {response.status_code}")
                break
            
            data = response.json()
            if "rows" in data and data["rows"]:
                new_quotes = [
                    {"quote": row["row"].get("quote", "No quote available"), 
                     "author": row["row"].get("author", "Unknown")}
                    for row in data["rows"]
                ]
                total_quotes.extend(new_quotes)
                offset += batch_size
                print(f"âœ… {len(new_quotes)} citations rÃ©cupÃ©rÃ©es, total : {len(total_quotes)}")
            else:
                print(f"âš ï¸ L'API a retournÃ© 0 rÃ©sultats Ã  offset={offset}. ArrÃªt.")
                break

        cached_quotes = total_quotes  # âœ… Stocke les citations rÃ©cupÃ©rÃ©es
        print(f"âœ… {len(cached_quotes)} citations mises en cache !")
        return cached_quotes  

@app.get("/quotes")
async def get_quotes():
    return await fetch_quotes()

# âœ… Fonction de normalisation du texte
def normalize_text(text):
    return re.sub(r"\s+", " ", text.strip().lower())

@app.get("/quotes/search")
async def search_quotes(query: str = Query(..., min_length=2)):
    all_quotes = await fetch_quotes()
    print(f"âœ… {len(all_quotes)} citations chargÃ©es pour la recherche.")
    query_norm = normalize_text(query)

    print(f"ðŸ”Ž Recherche pour '{query_norm}' dans {len(all_quotes)} citations...")
    result = []
    seen_texts = set()

    for q in all_quotes:
        quote_norm = normalize_text(q["quote"])
        author_norm = normalize_text(q["author"])

        if query_norm in quote_norm or query_norm in author_norm:
            if q["quote"] not in seen_texts:
                seen_texts.add(q["quote"])
                result.append(q)
        
        author_reversed = " ".join(reversed(author_norm.split(", ")))
        if query_norm in author_reversed:
            if q["quote"] not in seen_texts:
                seen_texts.add(q["quote"])
                result.append(q)

    print(f"âœ… {len(result)} rÃ©sultats trouvÃ©s pour '{query_norm}'")
    return result
